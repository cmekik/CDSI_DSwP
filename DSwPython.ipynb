{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"CDSI_Fac.of.Sc_logo.png\" alt=\"CDSI Logo\" height=\"100\"/>\n",
    "<img src=\"mcgill_ccr_approval_croppedforblock_0.png\" alt=\"CCR Approved Logo\" height=\"100\"/>\n",
    "\n",
    "# Data Science with Python (Pandas)\n",
    "\n",
    "\n",
    "Do you want to get into the state-of-the-art way of doing data science in academia? \n",
    "\n",
    "Register for this workshop where you will learn the first steps of importing, manipulating and cleaning data sets in Python using the pandas package.\n",
    "\n",
    "At the end of this workshop, you will be able to\n",
    "- Import data sets of different file formats\n",
    "- Understand the structure of pandas DataFrames\n",
    "- Apply common data wrangling functions (subset, reshape, merge, etc.)\n",
    "- Understand method chaining (AKA piping)\n",
    "- Apply different methods to treat missing values\n",
    "\n",
    "Pre-requisites? Introductory understanding of Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Introductory Remarks\n",
    "\n",
    "This workshop assumes minimal working knowledge of Python. \n",
    "\n",
    "Pandas is a great place to start using Python for data science\n",
    "- Similar feel to other stats software like R or Stata\n",
    "- Works well on its own but also integrates well with the Python data science ecosystem\n",
    "\n",
    "`Pandas` is excellent for [Data Wrangling](https://en.wikipedia.org/wiki/Data_wrangling), our main topic. \n",
    "\n",
    "This is the process making raw data ready for statistical analysis and/or modeling.\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. Python Review\n",
    "2. Installing and Importing Pandas\n",
    "3. Pandas Datastructures\n",
    "    - Series\n",
    "    - DataFrames\n",
    "    - Indexing & Subsetting\n",
    "    - Creating, Dropping & Renaming Columns\n",
    "4. Basic Data Wrangling\n",
    "    - Reading and Writing Data\n",
    "    - Viewing Data\n",
    "    - Adjusting Datatypes\n",
    "    - Cleaning Up Categorical Variables\n",
    "    - Calculating New Variables\n",
    "        - Transforming & Filtering Data by Groups\n",
    "        - Method Chaining (AKA Piping)\n",
    "    - Handling Missing Values\n",
    "    - Subsetting the Data\n",
    "5. More Data Wrangling\n",
    "    - Aggregating Data by Groups\n",
    "    - Concatenation\n",
    "    - Merging\n",
    "    - Reshaping\n",
    "6. Data Exploration\n",
    "    - Summary Statistics\n",
    "    - Basic Plotting \n",
    "    - Exporting Tables\n",
    "7. Advanced Topics\n",
    "    - A peek at `statsmodels`\n",
    "    - A peek at `numpy`\n",
    "\n",
    "## Useful Resources\n",
    "\n",
    "The [Pandas Cheatsheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf) is an excellent two-page summary of essential `pandas` features.\n",
    "\n",
    "The [Official Pandas Docs](https://pandas.pydata.org/docs/) are the single best resource for information on `pandas` short of the source code.\n",
    "\n",
    "If you are looking to learn about a specific function or feature, go into the API section.\n",
    "\n",
    "The docs also offer tutorials and other helpful material."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = []\n",
    "\n",
    "def func(__1, __2, __3, four, five, *more, **keywords):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and Importing `Pandas`\n",
    "\n",
    "`pandas` is fairly easy to install if you have Python, and it comes pre-packaged\n",
    "in Anaconda.\n",
    "\n",
    "If you have the `conda` package manager but no `pandas` installation, you can\n",
    "simply run the following code in your console, and follow any prompts that pop\n",
    "up. \n",
    "\n",
    "```conda install pandas```\n",
    "\n",
    "If you don't have Anaconda, but you have a python installation, you can also\n",
    "try the following code. \n",
    "\n",
    "```pip install pandas```\n",
    "\n",
    "Base `pandas` has only a few dependencies. You may also have to install optional\n",
    "dependencies depending on your work and your setup.\n",
    "\n",
    "For a full list of optional dependencies see the\n",
    "[Installation Documentation](https://pandas.pydata.org/docs/getting_started/install.html)\n",
    "\n",
    "You import `pandas` like any python package, as below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 'as' to define a short name for pandas \n",
    "# Otherwise you'll need to spell out 'pandas' every time\n",
    "# `pd` is a common abbreviation for `pandas`\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essential `pandas` Datastructures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series.cat\n",
    "# df.index # Returns the row index\n",
    "# df.columns # Returns the column index, handy for getting variable names.\n",
    "# dtypes\n",
    "# loc\n",
    "# iloc\n",
    "# etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Data Wrangling\n",
    "\n",
    "You can divide data wrangling into three broad activities.\n",
    "1. Inspection - Get familiar with the data and check for potential problems\n",
    "2. Preparation - Creating or cleaning variables, dealing with missing values\n",
    "3. Exploration - Computing descriptives statistics and identifying basic patterns in the data\n",
    "\n",
    "The ordering above is typical, but not absolute. The different activities often tend to blend together. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and Writing Data\n",
    "\n",
    "`pandas` can import a wide variety of common data formats. \n",
    "\n",
    "Some supported file types include the following.\n",
    "- CSV\n",
    "- Fixed Width\n",
    "- Excel\n",
    "- HTML tables\n",
    "- SAS\n",
    "- SPSS\n",
    "- STATA\n",
    "\n",
    "For a full list, see the [I/O documentation](https://pandas.pydata.org/docs/reference/io.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load data, call the appropriate 'read' function, like below \n",
    "df = pd.read_csv(\"federal-candidates-2021-10-20.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing to these formats is also generally supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To write a dataframe, call the write method for the chosen format\n",
    "df.to_csv(\"federal-candidates-copy.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and write functions have many optional parameters.\n",
    "\n",
    "You can use these parameters to control formatting, metadata, and more. \n",
    "\n",
    "These parameters can save you a lot of time, so be sure to check the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we are exporting the data to excel. \n",
    "# We specify the sheet name as well as the representation for missing values. \n",
    "# Be warned, this code may not behave well depending on your Python environment. Read on.\n",
    "# df.to_excel(\"federal-candidates.xlsx\", sheet_name=\"Candidate Data\", na_rep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, read/write functions may throw a `ModuleNotFoundError`.\n",
    "\n",
    "If so, that's because you are missing one of the optional dependencies.\n",
    "\n",
    "It might be alarming at first, but it's an easy fix, if a bit tedious. \n",
    "\n",
    "First, install the missing dependency into the current Python environment.\n",
    "\n",
    "There are a few ways to do this:\n",
    "\n",
    "- Using conda: \n",
    "    1. In the following code snippet, replace `<dependency>` with the name of the dependency.   \n",
    "    ```conda install <dependency>```\n",
    "    2.  Run the resulting code in your console (powershell for windows, terminal for mac/linux).\n",
    "- Using pip: Do the same as above, but with the following code snippet instead.  \n",
    "```pip install <dependency>```\n",
    "\n",
    "The methods above are not fail-safe but should work in nearly all cases.\n",
    "\n",
    "Then, restart the notebook and run everything again.\n",
    "\n",
    "If you don't restart the notebook, the new package will not be available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing the Data\n",
    "\n",
    "The first step in analyzing data is to get familiar with it.\n",
    "\n",
    "This way, you can get a feel for how much cleaning will be necessary and give yourself a chance to catch anything weird.\n",
    "\n",
    "`pandas` provides several utilities for this.\n",
    "\n",
    "First, take a look at the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() # General metadata: Information on indices, variable datatypes, and memory usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good next step is to inspect the data directly and continue to look for\n",
    "anything weird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10) # Peek at the first n rows. See anything weird?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other functions, that let us look at the bottom of the dataset or to\n",
    "randomly sample rows from the data set. These are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(10) # Peek at the last n rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10) # Peek at a random sample of rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting Datatypes\n",
    "\n",
    "Sometimes pandas fails to assign the right dtype when constructing a variable.\n",
    "So, our first step is to clean up the data types. \n",
    "\n",
    "String data are typically assigned the 'object' type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cols = df.select_dtypes(include=\"object\").columns\n",
    "print(f\"Object-type columns: {object_cols}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, almost all columns with string data represent categorical\n",
    "variables. \n",
    "\n",
    "One exception to this rule is edate, which represents a date. Furthermore,\n",
    "candidate_name and occupation are both a free-form strings.\n",
    "\n",
    "We can cast the affected variables to the correct dtypes as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.edate = pd.to_datetime(df.edate, yearfirst=True) \n",
    "\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    if col not in [\"candidate_name\", \"occupation\"]: \n",
    "        df[col] = df[col].astype(\"category\")\n",
    "\n",
    "df[object_cols].dtypes # Check what happened to the object-type columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's take a look at the numerical data.\n",
    "\n",
    "Do you notice anything weird?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_cols = df.select_dtypes(\"float\").columns\n",
    "print(f\"Float columns: {float_cols}\")\n",
    "\n",
    "int_cols = df.select_dtypes(\"int\").columns\n",
    "print(f\"Int columns: {int_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the four float columns, it is only natural to represent percent_votes as a \n",
    "float type variable. \n",
    "\n",
    "For riding_id, we are better off using a categorical datatype, even though the \n",
    "values look like integers. Likewise, the id column should also be viewed as a\n",
    "categorical. In both cases, the ordering of the values is not meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.riding_id = df.riding_id.astype(\"category\")\n",
    "df.id = df.id.astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the other two float columns, we should be using an integer dtype.\n",
    "\n",
    "But why were three variables get 'mis-coded' as float in the first place? \n",
    "\n",
    "It's because the default integer datatype in pandas does not support missing\n",
    "values, and these variables have missing values.\n",
    "\n",
    "Luckily, `pandas` has another integer datatype that supports missing values. We\n",
    "can just cast to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't mix up 'int64' with 'Int64'! In pandas, they are different: \n",
    "#   - 'int64' refers to the regular int type that has no missing value support\n",
    "#   - 'Int64' refers to the to the int type with missing value support\n",
    "\n",
    "df.birth_year = df.birth_year.astype(\"Int64\")\n",
    "df.votes = df.votes.astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's good to occasionally check if we did things right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Index.union() allows us to combine the two indices we isolated eariler.\n",
    "# You could also just do float_cols.union(int_cols), but I wanted to be explicit\n",
    "df[pd.Index.union(float_cols, int_cols)].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, let's take a moment to admire our work. Notice that a lot of\n",
    "the weird stuff is gone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Up Categorical Variables\n",
    "\n",
    "Categorical variables tend to require some extra attention, even in the most\n",
    "well-curated datasets.\n",
    "\n",
    "We often want to make adjustments.\n",
    "\n",
    "Let's take a look, for instance, at the values of the `gender` variable, keeping\n",
    "in mind what the data's README file says about this variable:\n",
    "> gender is a binary factor variable encoding candidate gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['2', 'F', 'M'], dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.gender.cat.categories # This is how we access category names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were told this is supposed to be a binary variable, but we got three values?\n",
    "\n",
    "So what's going on here? To get a better idea, let's tabulate the variable \n",
    "using the `Series.value_counts()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    39938\n",
       "F     6585\n",
       "2        2\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.gender.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phew! It only looks like a couple of entries were somehow miscoded. \n",
    "\n",
    "We can easily fix something like this by recoding the data using the \n",
    "`Series.replace()` method.\n",
    "\n",
    "In this case, we'll just send those to cases to a missing value, but we could\n",
    "assign any value we want to them using essentially the same technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['F', 'M'], dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.gender = df.gender.replace({\"2\": None})\n",
    "df.gender.cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another adjustment we can make is to rename categories. \n",
    "\n",
    "The main reason to do this is that it is confusing and difficult to work with\n",
    "poorly named data values. But, it can also come in handy when producing reports.\n",
    "\n",
    "Take a look at the category names in the `censuscategory` variable, which gives\n",
    "candidates' occupation according to the Census Canada taxonomy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Business, finance and administration occupations',\n",
       "       'Health occupations', 'Management occupations', 'Members of Parliament',\n",
       "       'Natural and applied sciences and related occupations',\n",
       "       'Natural resources, agriculture and related production occupations',\n",
       "       'Occupations in art, culture, recreation and sport',\n",
       "       'Occupations in education, law and social, community and government services',\n",
       "       'Occupations in manufacturing and utilities',\n",
       "       'Sales and service occupations',\n",
       "       'Trades, transport and equipment operators and related occupations'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.censuscategory.cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These names are precise, but wordy. We can abbreviate them using the \n",
    "`Series.cat.rename_categories()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Sales\n",
       "1       Sales\n",
       "2      Social\n",
       "3      Social\n",
       "4      Health\n",
       "5    Business\n",
       "6         NaN\n",
       "7      Social\n",
       "8      Health\n",
       "9         NaN\n",
       "Name: censuscategory, dtype: category\n",
       "Categories (11, object): ['Business', 'Health', 'Management', 'MP', ..., 'Social', 'Manufacturing', 'Sales', 'Trades']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We could pass in a dictionary to be extra explicit, but that would involve a\n",
    "# lot of copying. Since categories are ordered, we can just pass in a list with\n",
    "# abbreviations enumerated in the correct order.\n",
    "df.censuscategory = df.censuscategory.cat.rename_categories([\n",
    "    \"Business\", \"Health\", \"Management\", \"MP\", \"Science\", \"Resources\", \"Culture\",\n",
    "    \"Social\", \"Manufacturing\", \"Sales\", \"Trades\"\n",
    "])\n",
    "df.censuscategory.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsetting Data\n",
    "\n",
    "Often, we are not interested in the entirety of the data. \n",
    "\n",
    "Perhaps we care about only certain variables, or we care about only certain\n",
    "rows, and we may want to restrict our data to only those cases.\n",
    "\n",
    "There are several ways to do this, depending on the circumstance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7bb8eae9c2297506b9894494f89ab8d67c41d115c2354c72d7d438870909f850"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
